"""
Voice processing background tasks
Conversation cleanup, audio processing, and performance optimization
"""
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from celery import Task
import asyncio

from app.tasks.celery_app import celery_app
from app.core.database import AsyncSessionLocal
from app.services.voice_service import VoiceService
from app.services.analytics_service import AnalyticsService
from app.models.conversation import Conversation, ConversationStatus
from app.models.voice_agent import VoiceAgent

logger = logging.getLogger("seiketsu.voice_tasks")


class VoiceTask(Task):
    """Base task for voice operations"""
    
    def __init__(self):
        self.voice_service = VoiceService()
        self.analytics_service = AnalyticsService()


@celery_app.task(base=VoiceTask)
def cleanup_expired_conversations():
    """Clean up expired and stale conversations"""
    try:
        logger.info("Starting conversation cleanup")
        
        async def cleanup():
            async with AsyncSessionLocal() as db:
                from sqlalchemy import select, and_
                
                # Define cleanup criteria
                now = datetime.utcnow()
                
                # Conversations older than 24 hours and still active
                stale_cutoff = now - timedelta(hours=24)
                
                # Conversations older than 7 days (for archival)
                archive_cutoff = now - timedelta(days=7)
                
                # Get stale active conversations
                stale_stmt = select(Conversation).where(\n                    and_(\n                        Conversation.is_active == True,\n                        Conversation.started_at < stale_cutoff\n                    )\n                )\n                \n                stale_result = await db.execute(stale_stmt)\n                stale_conversations = stale_result.scalars().all()\n                \n                stale_count = 0\n                for conv in stale_conversations:\n                    try:\n                        # Mark as ended due to timeout\n                        conv.status = ConversationStatus.ENDED\n                        conv.is_active = False\n                        conv.ended_at = now\n                        conv.duration_seconds = int((now - conv.started_at).total_seconds())\n                        \n                        # Add timeout note\n                        if not conv.notes:\n                            conv.notes = \"\"\n                        conv.notes += f\"\\n[{now.isoformat()}] Conversation ended due to inactivity timeout\"\n                        \n                        stale_count += 1\n                        \n                    except Exception as e:\n                        logger.error(f\"Failed to cleanup conversation {conv.id}: {e}\")\n                        continue\n                \n                # Get old conversations for archival\n                archive_stmt = select(Conversation).where(\n                    and_(\n                        Conversation.started_at < archive_cutoff,\n                        Conversation.archived == False\n                    )\n                )\n                \n                archive_result = await db.execute(archive_stmt)\n                archive_conversations = archive_result.scalars().all()\n                \n                archive_count = 0\n                for conv in archive_conversations:\n                    try:\n                        conv.archived = True\n                        archive_count += 1\n                    except Exception as e:\n                        logger.error(f\"Failed to archive conversation {conv.id}: {e}\")\n                        continue\n                \n                await db.commit()\n                \n                logger.info(f\"Cleaned up {stale_count} stale conversations, archived {archive_count} old conversations\")\n                return {\"stale_cleaned\": stale_count, \"archived\": archive_count}\n        \n        return asyncio.run(cleanup())\n        \n    except Exception as e:\n        logger.error(f\"Conversation cleanup failed: {e}\")\n        raise\n\n\n@celery_app.task(bind=True, base=VoiceTask)\ndef process_conversation_analytics(\n    self,\n    conversation_id: str\n):\n    \"\"\"Process analytics for completed conversation\"\"\"\n    try:\n        async def process_analytics():\n            async with AsyncSessionLocal() as db:\n                from sqlalchemy import select\n                \n                # Get conversation\n                stmt = select(Conversation).where(Conversation.id == conversation_id)\n                result = await db.execute(stmt)\n                conversation = result.scalar_one_or_none()\n                \n                if not conversation:\n                    logger.warning(f\"Conversation {conversation_id} not found\")\n                    return {\"status\": \"conversation_not_found\"}\n                \n                # Calculate conversation metrics\n                metrics = {\n                    \"duration_seconds\": conversation.duration_seconds or 0,\n                    \"status\": conversation.status.value,\n                    \"lead_generated\": bool(conversation.lead_id),\n                    \"sentiment_score\": conversation.sentiment_score,\n                    \"transferred_to_human\": conversation.transferred_to_human,\n                    \"voice_agent_id\": conversation.voice_agent_id,\n                    \"organization_id\": conversation.organization_id\n                }\n                \n                # Track analytics event\n                await self.analytics_service.track_event(\n                    \"conversation\", \"completed\", conversation.organization_id, db,\n                    conversation_id=conversation_id,\n                    voice_agent_id=conversation.voice_agent_id,\n                    properties=metrics\n                )\n                \n                # Update voice agent statistics\n                await self._update_agent_statistics(conversation.voice_agent_id, metrics, db)\n                \n                logger.info(f\"Processed analytics for conversation {conversation_id}\")\n                return {\"status\": \"processed\", \"metrics\": metrics}\n        \n        return asyncio.run(process_analytics())\n        \n    except Exception as e:\n        logger.error(f\"Failed to process conversation analytics: {e}\")\n        raise\n\n\n@celery_app.task(bind=True, base=VoiceTask)\ndef optimize_voice_agent_performance(\n    self,\n    agent_id: str\n):\n    \"\"\"Optimize voice agent performance based on recent data\"\"\"\n    try:\n        async def optimize_performance():\n            async with AsyncSessionLocal() as db:\n                from sqlalchemy import select, and_\n                \n                # Get voice agent\n                agent_stmt = select(VoiceAgent).where(VoiceAgent.id == agent_id)\n                agent_result = await db.execute(agent_stmt)\n                agent = agent_result.scalar_one_or_none()\n                \n                if not agent:\n                    return {\"status\": \"agent_not_found\"}\n                \n                # Get recent conversations for analysis\n                recent_cutoff = datetime.utcnow() - timedelta(days=7)\n                conv_stmt = select(Conversation).where(\n                    and_(\n                        Conversation.voice_agent_id == agent_id,\n                        Conversation.started_at >= recent_cutoff\n                    )\n                )\n                \n                conv_result = await db.execute(conv_stmt)\n                conversations = conv_result.scalars().all()\n                \n                if len(conversations) < 5:\n                    return {\"status\": \"insufficient_data\"}\n                \n                # Analyze performance metrics\n                performance_analysis = self._analyze_agent_performance(conversations)\n                \n                # Generate optimization recommendations\n                optimizations = self._generate_optimizations(performance_analysis)\n                \n                # Apply automatic optimizations if safe\n                applied_optimizations = await self._apply_safe_optimizations(\n                    agent, optimizations, db\n                )\n                \n                logger.info(f\"Optimized agent {agent_id}: {applied_optimizations} changes applied\")\n                return {\n                    \"status\": \"optimized\",\n                    \"analysis\": performance_analysis,\n                    \"recommendations\": optimizations,\n                    \"applied\": applied_optimizations\n                }\n        \n        return asyncio.run(optimize_performance())\n        \n    except Exception as e:\n        logger.error(f\"Voice agent optimization failed: {e}\")\n        raise\n\n\n@celery_app.task(bind=True, base=VoiceTask)\ndef generate_voice_performance_report(\n    self,\n    organization_id: str,\n    days: int = 7\n):\n    \"\"\"Generate voice performance reports\"\"\"\n    try:\n        async def generate_report():\n            async with AsyncSessionLocal() as db:\n                # Get voice agent performance\n                agent_performance = await self.analytics_service.get_voice_agent_performance(\n                    organization_id, db, days=days\n                )\n                \n                # Get conversation metrics\n                conversation_metrics = await self.analytics_service.get_conversation_metrics(\n                    organization_id, db, days=days\n                )\n                \n                # Generate insights and recommendations\n                insights = self._generate_performance_insights(\n                    agent_performance, conversation_metrics\n                )\n                \n                # Store report\n                report = {\n                    \"organization_id\": organization_id,\n                    \"generated_at\": datetime.utcnow().isoformat(),\n                    \"period_days\": days,\n                    \"agent_performance\": agent_performance,\n                    \"conversation_metrics\": conversation_metrics,\n                    \"insights\": insights\n                }\n                \n                # Cache report for quick access\n                from app.core.cache import cache_analytics_data\n                await cache_analytics_data(\n                    organization_id, f\"voice_performance_report_{days}d\", report, ttl=3600\n                )\n                \n                logger.info(f\"Generated voice performance report for org {organization_id}\")\n                return report\n        \n        return asyncio.run(generate_report())\n        \n    except Exception as e:\n        logger.error(f\"Voice performance report generation failed: {e}\")\n        raise\n\n\n@celery_app.task(bind=True, base=VoiceTask)\ndef process_voice_quality_metrics(\n    self,\n    conversation_id: str,\n    audio_quality_data: Dict[str, Any]\n):\n    \"\"\"Process voice quality metrics for conversation\"\"\"\n    try:\n        async def process_quality():\n            async with AsyncSessionLocal() as db:\n                from sqlalchemy import select\n                \n                # Get conversation\n                stmt = select(Conversation).where(Conversation.id == conversation_id)\n                result = await db.execute(stmt)\n                conversation = result.scalar_one_or_none()\n                \n                if not conversation:\n                    return {\"status\": \"conversation_not_found\"}\n                \n                # Process quality metrics\n                quality_score = self._calculate_quality_score(audio_quality_data)\n                \n                # Update conversation with quality data\n                if not conversation.metadata:\n                    conversation.metadata = {}\n                \n                conversation.metadata[\"audio_quality\"] = {\n                    \"score\": quality_score,\n                    \"metrics\": audio_quality_data,\n                    \"processed_at\": datetime.utcnow().isoformat()\n                }\n                \n                await db.commit()\n                \n                # Track quality analytics\n                await self.analytics_service.track_event(\n                    \"voice\", \"quality_processed\", conversation.organization_id, db,\n                    conversation_id=conversation_id,\n                    properties={\n                        \"quality_score\": quality_score,\n                        \"audio_duration\": audio_quality_data.get(\"duration_seconds\", 0)\n                    }\n                )\n                \n                logger.info(f\"Processed voice quality for conversation {conversation_id}\")\n                return {\"status\": \"processed\", \"quality_score\": quality_score}\n        \n        return asyncio.run(process_quality())\n        \n    except Exception as e:\n        logger.error(f\"Voice quality processing failed: {e}\")\n        raise\n\n\n@celery_app.task(bind=True, base=VoiceTask)\ndef update_voice_agent_availability(\n    self,\n    agent_id: str\n):\n    \"\"\"Update voice agent availability based on performance and load\"\"\"\n    try:\n        async def update_availability():\n            async with AsyncSessionLocal() as db:\n                from sqlalchemy import select, and_\n                \n                # Get voice agent\n                agent_stmt = select(VoiceAgent).where(VoiceAgent.id == agent_id)\n                agent_result = await db.execute(agent_stmt)\n                agent = agent_result.scalar_one_or_none()\n                \n                if not agent:\n                    return {\"status\": \"agent_not_found\"}\n                \n                # Check current load (active conversations)\n                now = datetime.utcnow()\n                active_conv_stmt = select(Conversation).where(\n                    and_(\n                        Conversation.voice_agent_id == agent_id,\n                        Conversation.is_active == True\n                    )\n                )\n                \n                active_result = await db.execute(active_conv_stmt)\n                active_conversations = active_result.scalars().all()\n                \n                current_load = len(active_conversations)\n                max_concurrent = agent.max_concurrent_calls or 5\n                \n                # Update availability status\n                if current_load >= max_concurrent:\n                    agent.availability_status = \"busy\"\n                elif current_load >= max_concurrent * 0.8:\n                    agent.availability_status = \"limited\"\n                else:\n                    agent.availability_status = \"available\"\n                \n                # Update last_activity\n                agent.last_activity = now\n                \n                await db.commit()\n                \n                # Cache status for quick access\n                from app.core.cache import cache_voice_agent_status\n                await cache_voice_agent_status(\n                    agent_id,\n                    {\n                        \"availability_status\": agent.availability_status,\n                        \"current_load\": current_load,\n                        \"max_concurrent\": max_concurrent,\n                        \"last_updated\": now.isoformat()\n                    },\n                    ttl=30\n                )\n                \n                logger.debug(f\"Updated availability for agent {agent_id}: {agent.availability_status}\")\n                return {\n                    \"status\": \"updated\",\n                    \"availability\": agent.availability_status,\n                    \"load\": f\"{current_load}/{max_concurrent}\"\n                }\n        \n        return asyncio.run(update_availability())\n        \n    except Exception as e:\n        logger.error(f\"Voice agent availability update failed: {e}\")\n        raise\n\n\n# Helper methods\nasync def _update_agent_statistics(self, agent_id: str, metrics: Dict[str, Any], db):\n    \"\"\"Update voice agent statistics\"\"\"\n    try:\n        from sqlalchemy import select\n        \n        stmt = select(VoiceAgent).where(VoiceAgent.id == agent_id)\n        result = await db.execute(stmt)\n        agent = result.scalar_one_or_none()\n        \n        if agent:\n            # Update total conversations\n            agent.total_conversations = (agent.total_conversations or 0) + 1\n            \n            # Update success rate (if lead was generated)\n            if metrics.get(\"lead_generated\"):\n                agent.successful_calls = (agent.successful_calls or 0) + 1\n            \n            # Calculate success rate\n            if agent.total_conversations > 0:\n                agent.success_rate = (agent.successful_calls or 0) / agent.total_conversations * 100\n            \n            # Update average call duration\n            duration = metrics.get(\"duration_seconds\", 0)\n            if duration > 0:\n                current_avg = agent.average_call_duration or 0\n                total_calls = agent.total_conversations\n                agent.average_call_duration = (\n                    (current_avg * (total_calls - 1)) + duration\n                ) / total_calls\n            \n            agent.last_activity = datetime.utcnow()\n            await db.commit()\n    \n    except Exception as e:\n        logger.error(f\"Failed to update agent statistics: {e}\")\n\n\ndef _analyze_agent_performance(self, conversations: List[Conversation]) -> Dict[str, Any]:\n    \"\"\"Analyze agent performance from recent conversations\"\"\"\n    if not conversations:\n        return {}\n    \n    total_conversations = len(conversations)\n    completed_conversations = len([c for c in conversations if c.status == ConversationStatus.COMPLETED])\n    leads_generated = len([c for c in conversations if c.lead_id])\n    \n    # Duration analysis\n    durations = [c.duration_seconds for c in conversations if c.duration_seconds]\n    avg_duration = sum(durations) / len(durations) if durations else 0\n    \n    # Sentiment analysis\n    sentiments = [c.sentiment_score for c in conversations if c.sentiment_score is not None]\n    avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0\n    \n    # Transfer rate\n    transfers = len([c for c in conversations if c.transferred_to_human])\n    \n    return {\n        \"total_conversations\": total_conversations,\n        \"completion_rate\": (completed_conversations / total_conversations) * 100,\n        \"lead_conversion_rate\": (leads_generated / total_conversations) * 100,\n        \"average_duration\": avg_duration,\n        \"average_sentiment\": avg_sentiment,\n        \"transfer_rate\": (transfers / total_conversations) * 100,\n        \"performance_score\": self._calculate_performance_score(\n            completed_conversations / total_conversations,\n            leads_generated / total_conversations,\n            avg_sentiment\n        )\n    }\n\n\ndef _calculate_performance_score(self, completion_rate: float, conversion_rate: float, sentiment: float) -> float:\n    \"\"\"Calculate overall performance score\"\"\"\n    # Weighted performance score\n    score = (\n        (completion_rate * 0.3) +\n        (conversion_rate * 0.4) +\n        ((sentiment + 1) * 50 * 0.3)  # Normalize sentiment to 0-100 scale\n    )\n    return max(0, min(100, score))\n\n\ndef _generate_optimizations(self, performance_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"Generate optimization recommendations\"\"\"\n    optimizations = []\n    \n    # Completion rate optimization\n    if performance_analysis.get(\"completion_rate\", 0) < 70:\n        optimizations.append({\n            \"type\": \"completion_rate\",\n            \"recommendation\": \"Improve conversation flow to reduce drop-offs\",\n            \"priority\": \"high\",\n            \"action\": \"review_conversation_scripts\"\n        })\n    \n    # Conversion rate optimization\n    if performance_analysis.get(\"lead_conversion_rate\", 0) < 20:\n        optimizations.append({\n            \"type\": \"conversion_rate\",\n            \"recommendation\": \"Enhance qualification questions and lead capture\",\n            \"priority\": \"high\",\n            \"action\": \"update_qualification_process\"\n        })\n    \n    # Sentiment optimization\n    if performance_analysis.get(\"average_sentiment\", 0) < -0.1:\n        optimizations.append({\n            \"type\": \"sentiment\",\n            \"recommendation\": \"Improve conversation tone and empathy\",\n            \"priority\": \"medium\",\n            \"action\": \"adjust_response_style\"\n        })\n    \n    # Duration optimization\n    avg_duration = performance_analysis.get(\"average_duration\", 0)\n    if avg_duration > 600:  # 10 minutes\n        optimizations.append({\n            \"type\": \"duration\",\n            \"recommendation\": \"Optimize conversation length for efficiency\",\n            \"priority\": \"medium\",\n            \"action\": \"streamline_conversation_flow\"\n        })\n    elif avg_duration < 60:  # 1 minute\n        optimizations.append({\n            \"type\": \"duration\",\n            \"recommendation\": \"Increase engagement time to improve qualification\",\n            \"priority\": \"medium\",\n            \"action\": \"extend_qualification_process\"\n        })\n    \n    return optimizations\n\n\nasync def _apply_safe_optimizations(\n    self, \n    agent: VoiceAgent, \n    optimizations: List[Dict[str, Any]], \n    db\n) -> int:\n    \"\"\"Apply safe, automatic optimizations\"\"\"\n    applied_count = 0\n    \n    for optimization in optimizations:\n        try:\n            if optimization[\"action\"] == \"adjust_response_style\" and optimization[\"priority\"] == \"medium\":\n                # Safely adjust response style parameters\n                if not agent.conversation_settings:\n                    agent.conversation_settings = {}\n                \n                # Make conversation slightly more empathetic\n                agent.conversation_settings[\"empathy_level\"] = min(\n                    agent.conversation_settings.get(\"empathy_level\", 0.5) + 0.1,\n                    1.0\n                )\n                applied_count += 1\n            \n            # Add more safe optimizations here\n            \n        except Exception as e:\n            logger.error(f\"Failed to apply optimization {optimization['type']}: {e}\")\n            continue\n    \n    if applied_count > 0:\n        await db.commit()\n    \n    return applied_count\n\n\ndef _generate_performance_insights(\n    self, \n    agent_performance: List[Dict[str, Any]], \n    conversation_metrics: Dict[str, Any]\n) -> Dict[str, Any]:\n    \"\"\"Generate performance insights from data\"\"\"\n    insights = {\n        \"top_performing_agents\": [],\n        \"areas_for_improvement\": [],\n        \"trending_metrics\": {},\n        \"recommendations\": []\n    }\n    \n    if agent_performance:\n        # Sort by performance score\n        sorted_agents = sorted(\n            agent_performance, \n            key=lambda x: x.get(\"lead_conversion_rate\", 0), \n            reverse=True\n        )\n        \n        insights[\"top_performing_agents\"] = sorted_agents[:3]\n        \n        # Identify improvement areas\n        avg_conversion = sum(a.get(\"lead_conversion_rate\", 0) for a in agent_performance) / len(agent_performance)\n        avg_sentiment = sum(a.get(\"average_sentiment_score\", 0) for a in agent_performance) / len(agent_performance)\n        \n        if avg_conversion < 25:\n            insights[\"areas_for_improvement\"].append(\"Overall lead conversion rate is below target\")\n        \n        if avg_sentiment < 0.1:\n            insights[\"areas_for_improvement\"].append(\"Customer sentiment scores need improvement\")\n    \n    # Add conversation-level insights\n    completion_rate = conversation_metrics.get(\"completion_rate\", 0)\n    if completion_rate < 80:\n        insights[\"recommendations\"].append(\"Focus on reducing conversation drop-off rates\")\n    \n    transfer_rate = conversation_metrics.get(\"transfer_rate\", 0)\n    if transfer_rate > 15:\n        insights[\"recommendations\"].append(\"High transfer rate indicates need for agent training\")\n    \n    return insights\n\n\ndef _calculate_quality_score(self, audio_data: Dict[str, Any]) -> float:\n    \"\"\"Calculate audio quality score from metrics\"\"\"\n    # This would analyze actual audio metrics\n    # For now, return a mock score based on available data\n    \n    score = 100.0\n    \n    # Penalize for poor audio quality indicators\n    if audio_data.get(\"noise_level\", 0) > 0.3:\n        score -= 20\n    \n    if audio_data.get(\"clarity_score\", 1.0) < 0.7:\n        score -= 15\n    \n    if audio_data.get(\"volume_consistency\", 1.0) < 0.8:\n        score -= 10\n    \n    return max(0, min(100, score))